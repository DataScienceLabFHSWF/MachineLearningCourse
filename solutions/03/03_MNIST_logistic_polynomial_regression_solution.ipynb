{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cbad58a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "x = mnist.data\n",
    "y = mnist.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "506305ea",
   "metadata": {},
   "source": [
    "Analyze the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18447491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , mnist.data.shape)\n",
    "\n",
    "# Print to show there are 1797 labels (integers from 0-9)\n",
    "print(\"Label Data Shape\", mnist.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dad925",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d630da2",
   "metadata": {},
   "source": [
    "Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, test_img, train_lbl, test_lbl = train_test_split(\n",
    "    mnist.data, mnist.target, test_size=1/7.0, random_state=0)\n",
    "\n",
    "train_lbl.values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412dd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d4d91a4",
   "metadata": {},
   "source": [
    "Plot some of the training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(train_img.values[0:5], train_lbl.values[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % int(label), fontsize = 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af576c59",
   "metadata": {},
   "source": [
    "Import LogisticRegression module from sklearn, create a model and use the training data to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'saga', tol=1e-2, max_iter=1000)\n",
    "\n",
    "logisticRegr.fit(train_img.values, train_lbl.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a69c350",
   "metadata": {},
   "source": [
    " We can now predict the outcome for one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a NumPy Array\n",
    "print(f\"actual: {train_lbl.values[0]}   |   prediction: {logisticRegr.predict(train_img.values[0].reshape(1,-1))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85bb09c4",
   "metadata": {},
   "source": [
    "or multiple observations from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"actual values: {train_lbl.values[0:10]}\")\n",
    "print(f\"predicted values: {logisticRegr.predict(train_img.values[0:10])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb01a149",
   "metadata": {},
   "source": [
    "What we are really after though is the accuracy of our trained classifier on previously unseen data, that is what we created our test dataset for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd266a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on entire test data\n",
    "predictions = logisticRegr.predict(test_img.values)\n",
    "\n",
    "score = logisticRegr.score(test_img.values, test_lbl.values)\n",
    "print(f\"accuracy: {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e365a023",
   "metadata": {},
   "source": [
    "Here we predict the probability of each class for a single image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33082904",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_proba = logisticRegr.predict_proba(test_img)\n",
    "print(f\"prediction probabilities: {prediction_proba[0]}\")\n",
    "print(f\"sum over prediction probabilities: {sum(prediction_proba[0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52035824",
   "metadata": {},
   "source": [
    "In order to display misclassified results, we first need to know which images are actually wrongly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cf148",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(test_lbl.values, predictions):\n",
    "    if label != predict: \n",
    "        misclassifiedIndexes.append(index)\n",
    "    index +=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3722e3a7",
   "metadata": {},
   "source": [
    "Print the previously filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(test_img.values[badIndex], (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title('Predicted: {}, Actual: {}'.format(predictions[badIndex], test_lbl.values[badIndex]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_proba[misclassifiedIndexes[0:5]][4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd3f0daf",
   "metadata": {},
   "source": [
    "### Polynomial regression\n",
    "Why and when use Polynomial Regression instead of Linear Regression?\n",
    "\n",
    "\"There are 3 main situations that would warrant a Polynomial Regression over Linear:\n",
    "\n",
    "    The theoretical reason. The researcher (you) may hypothesise that the data will be curvilinear, in which case you should obviously fit it with a curve.\n",
    "    Upon a visual inspection of your data, a curvilinear relationship may be revealed. This could be achieved by a simple scatter plot (which is why you should always perform univariate and bivariate inspections of your data before applying a Regression Analysis).\n",
    "    Inspecting the model’s residuals. Attempting to fit a linear model to curvilinear data will result in high positive and negative residuals, and a low R² score.\" \n",
    "[[1]](https://towardsdatascience.com/polynomial-regression-the-only-introduction-youll-need-49a6fb2b86de)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "153d3939",
   "metadata": {},
   "source": [
    "Create data and split it into train and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 30)\n",
    "y = [3, 4, 5, 7, 10, 8, 9, 10, 10, 23, 27, 44, 50, 63, 67, 60, 62, 70, 75, 88, 81, 87, 95, 100, 108, 135,\n",
    "151, 160, 169, 179]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24946b47",
   "metadata": {},
   "source": [
    "Plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, c='#8acfd4', label='All data')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac541686",
   "metadata": {},
   "source": [
    "Plot train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef101a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train, c='#8acfd4', label='Training data')\n",
    "plt.scatter(x_test, y_test, c='#edbf6f', label='Testing data')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6abd4f7",
   "metadata": {},
   "source": [
    "#### Generate polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380aac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c69213d0",
   "metadata": {},
   "source": [
    "Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train).reshape(-1,1)\n",
    "x_test = np.array(x_test).reshape(-1,1)\n",
    "y_train = np.array(y_train).reshape(-1,1)\n",
    "y_test = np.array(y_test).reshape(-1,1)\n",
    "\n",
    "y_train = y_train[x_train[:,0].argsort()]\n",
    "y_test = y_test[x_test[:,0].argsort()]\n",
    "x_train = x_train[x_train[:,0].argsort()]\n",
    "x_test = x_test[x_test[:,0].argsort()]\n",
    "\n",
    "# two possibilities to reach the same goal:\n",
    "\n",
    "print(\"x_train.shape: {}  y_train.shape: {}\".format(x_train.shape,y_train.shape))\n",
    "print(\"x_train.shape: ({}, {})  y_train.shape: ({}, {})\".format(len(x_train),len(x_train[0]),len(y_train),len(y_train[0])))\n",
    "\n",
    "print(\"x_test.shape: {}  y_test.shape: {}\".format(x_test.shape,y_test.shape))\n",
    "print(\"x_test.shape: ({}, {})  y_test.shape: ({}, {})\".format(len(x_test),len(x_test[0]),len(y_test),len(y_test[0])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "399ce245",
   "metadata": {},
   "source": [
    "Create polynomial features objects and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98599f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "# x_test_poly = poly.transform(x_test)\n",
    "\n",
    "poly5 = PolynomialFeatures(degree=5)\n",
    "x_train_poly5 = poly5.fit_transform(x_train)\n",
    "\n",
    "poly10 = PolynomialFeatures(degree=10)\n",
    "x_train_poly10 = poly10.fit_transform(x_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6564f22c",
   "metadata": {},
   "source": [
    "Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(x_train_poly, y_train)\n",
    "\n",
    "poly5_reg = LinearRegression()\n",
    "poly5_reg.fit(x_train_poly5, y_train)\n",
    "\n",
    "poly10_reg = LinearRegression()\n",
    "poly10_reg.fit(x_train_poly10, y_train)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de1e687e",
   "metadata": {},
   "source": [
    "Plot models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Polynomial regression example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.scatter(x_train.reshape(-1,), y_train.reshape(-1,), c='#8acfd4', label='Training data')\n",
    "plt.scatter(x_test.reshape(-1,), y_test.reshape(-1,), c='#edbf6f', label='Testing data')\n",
    "plt.plot(x_train, poly_reg.predict(x_train_poly), c='#a3cfa3', label='Polynomial regression line (2 degress)')\n",
    "plt.plot(x_train, poly5_reg.predict(x_train_poly5), c='#0FF0FF', label='Polynomial regression line (5 degrees)')\n",
    "plt.plot(x_train, poly10_reg.predict(x_train_poly10), c='r', label='Polynomial regression line (10 degrees)')\n",
    "plt.plot(x_train, lin_reg.predict(x_train), c='#ffcff3', label='Linear regression line')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc1298",
   "metadata": {},
   "source": [
    "#### numpy.polyfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 30)\n",
    "y = [3, 4, 5, 7, 10, 8, 9, 10, 10, 23, 27, 44, 50, 63, 67, 60, 62, 70, 75, 88, 81, 87, 95, 100, 108, 135,\n",
    "151, 160, 169, 179]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da4c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=21)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = y_train[x_train[:,].argsort()]\n",
    "y_test = y_test[x_test[:,].argsort()]\n",
    "x_train = x_train[x_train[:,].argsort()]\n",
    "x_test = x_test[x_test[:,].argsort()]\n",
    "\n",
    "x_train_resh = x_train.reshape(-1,1)\n",
    "x_test_resh = x_test.reshape(-1,1)\n",
    "y_train_resh = y_train.reshape(-1,1)\n",
    "y_test_resh = y_test.reshape(-1,1)\n",
    "\n",
    "plt.title('Polynomial regression example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.scatter(x_train, y_train, c='#8acfd4', label='Training data')\n",
    "plt.scatter(x_test, y_test, c='#edbf6f', label='Testing data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cd206",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "# x_train_poly = poly.fit_transform(x_train)\n",
    "\n",
    "poly10_reg = LinearRegression()\n",
    "poly10_reg.fit(x_train_poly10, y_train)\n",
    "\n",
    "x_train_poly_np = np.polyfit(x_train,y_train, 10)\n",
    "x_test_poly_np = np.polyfit(x_test,y_test, 3)\n",
    "\n",
    "poly2d_fn = np.poly1d(x_train_poly_np)\n",
    "\n",
    "plt.title('Polynomial regression example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.scatter(x_train, y_train, c='#8acfd4', label='Training data')\n",
    "plt.scatter(x_test, y_test, c='#edbf6f', label='Testing data')\n",
    "plt.plot(x,poly2d_fn(x), label='Polynomial regression line (10 degrees) (np.polyfit)')\n",
    "plt.plot(x_train, poly10_reg.predict(x_train_poly10), c='r', label='Polynomial regression line (10 degrees) (PolynomialFeatures)')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Polynomial regression example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.scatter(x_train, y_train, c='#8acfd4', label='Training data')\n",
    "plt.scatter(x_test, y_test, c='#edbf6f', label='Testing data')\n",
    "plt.plot(x_train, poly_reg.predict(x_train_poly), c='#a3cfa3', label='Polynomial regression line (2 degress)')\n",
    "plt.plot(x_train, poly5_reg.predict(x_train_poly5), c='#0FF0FF', label='Polynomial regression line (5 degrees)')\n",
    "# plt.plot(x_train, poly10_reg.predict(x_train_poly10), c='r', label='Polynomial regression line (10 degrees)')\n",
    "# plt.plot(x_train, lin_reg.predict(x_train), c='#ffcff3', label='Linear regression line')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('airflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "568ce6a90abe48cd4c71813e2e18d608b5934a77a079188d46a97b4cb4032653"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
